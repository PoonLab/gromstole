#' The purpose of this script is to fit a (quasi)binomial model to 
#' the observed frequencies of mutations that are previously determined
#' to be characteristic of a specific lineage of SARS-CoV-2.  It is meant 
#' to be run on a set of CSV outputs generated by minimap2.py

# parse command line arguments
args <- commandArgs(trailingOnly = TRUE)
args <- c("results/waterloo/run13", "results/testprovoc", "uploads/waterloo/run13/metadata.csv")
if (length(args) < 2) {
  stop("\n\nUsage: Rscript estfreq.R [input dir] [lineage CSV] ",
       "[output JSON] (metadata)\n",
       "  input dir:  run folder of CSV files generated by minimap2.py\n",
       #"  constellation JSON:  path to JSON with constellation\n",
       "  output JSON:  path to write JSON of frequency estimates\n",
       "  metadata:  optional, path to metadata CSV file\n\n")
}
run.dir <- args[1]  # location of CSV outputs from minimap2.py
#stelfile <- #args[2]
outfile <- args[2]
metafile <- NA
if (length(args) > 2) {
  metafile <- args[3]
}

lineages <- c('BA.1', 'BA.2', 'B.1.617.2')


#' re.findall
#'
#' Emulate behaviour of Python's re.findall() function
#'
#' @param pat:  regex pattern
#' @param s:  character, a single string
#' @return character, vector of all matching substrings
re.findall <- function(pat, s) {
  if (!is.character(s)) {
    stop("re.findall() requires a character object for input 's'")
  }
  matches <- gregexpr(pat, s)
  index <- as.integer(matches[[1]])
  match.length <- attr(matches[[1]], 'match.length')
  
  sapply(1:length(index), function(i) {
    start <- index[i]
    stop <- start + match.length[i] - 1
    substr(s, start, stop)
  })
}

# coordinates of reading frames in reference
orfs <- list(
  'orf1a'= c(265, 13468),
  'orf1b'= c(13467, 21555),
  'S'= c(21562, 25384),
  'orf3a'= c(25392, 26220),
  'E'= c(26244, 26472),
  'M'= c(26522, 27191),
  'orf6'= c(27201, 27387),
  'orf7a'= c(27393, 27759),
  'orf7b'= c(27755, 27887),
  'orf8'= c(27893, 28259),
  'N'= c(28273, 29533),
  'orf10'= c(29557, 29674),
  'nsp2' = c(806, 2719),
  'nsp3' = c(2720, 8554),
  'nsp4' = c(8555, 10054),
  'nsp5' = c(10055, 10972),
  'nsp6' = c(10973, 11842),
  'nsp12' = c(13442, 16236),
  'nsp13' = c(16237, 18039),
  'nsp15' = c(19621, 20658)
)


require(lubridate)
require(jsonlite)
require(seqinr)

source("scripts/astronomize.R")
varmat <- astronomize(path = "constellations")
varmat <- varmat[row.names(varmat) %in% lineages,]
varmat <- varmat[, colSums(varmat) > 0]
sites <- colnames(varmat)

# locate data files
require(here)
mfiles <- list.files(here(run.dir), full.names = TRUE,
                     pattern=".+\\.mapped\\.csv$")
mfiles <- mfiles[!grepl("Undetermined", basename(mfiles))]
cfiles <- list.files(here(run.dir), full.names = TRUE,
                     pattern=".+\\.coverage\\.csv$")  
cfiles <- cfiles[!grepl("Undetermined", basename(cfiles))]

if(length(mfiles) == 0) 
  stop("No *.mapped.csv files found!")
if(length(cfiles) == 0) 
  stop("No *.coverage.csv files found!")
if(length(mfiles) != length(cfiles)) 
  stop("Mismatch between number of *.mapped.csv and *.coverage.csv files")


# import mutation frequency data
maps <- lapply(mfiles, function(f) {
  pos <- rep(NA, length(sites))
  names(pos) <- sites
  
  mapped <- read.csv(f, stringsAsFactors = FALSE)
  mapped$type <- substr(mapped$label, 1, 1)
  mapped$pos <- mapped$position+1
  mapped$alt <- sapply(strsplit(mapped$label, as.character(mapped$pos)), 
                       function(x) {
                         gsub("^\\.", "", x[2])
                       })
  
  mapped$label <- gsub("^~", "", mapped$label)
  index_label <- match(sites, mapped$label)
  
  # retrieve reference nucleotides for synonymous substitutions (nuc:)
  mapped$mutation[mapped$mutation=='None'] <- 
    paste(toupper(refseq[mapped$pos[mapped$mutation=='None']]), 
          mapped$label[mapped$mutation=='None'], sep='')
  index <- match(sites, mapped$mutation)
  
  for (i in 1:length(index)) {
    if (!is.na(index_label[i])) {
      index[[i]] <- index_label[[i]]
    }
    if (!is.na(index[[i]]) && is.na(pos[[i]])) {
      pos[i] <- mapped$pos[index[i]]
    }
  }
  list(counts=mapped$frequency[index], 
       coverage=mapped$coverage[index],
       pos=pos)
})

counts <- as.data.frame(sapply(maps, function(x) x$counts))
row.names(counts) <- sites

sample.id <- sapply(strsplit(mfiles, split = "/"), function(x) {
  strsplit(x[length(x)], split = "\\.")[[1]][1]
})
names(counts) <- sample.id

cvr <- as.data.frame(sapply(maps, function(x) x$coverage))
row.names(cvr) <- sites
names(cvr) <- sample.id

# determine nucleotide position of constellation mutations 
positions <- as.data.frame(sapply(maps, function(x) x$pos))
if (all(is.na(positions))) {
  pos <- rep(NA, length(sites))
} else {
  pos <- as.integer(apply(positions, 1, function(r) {
    tab <- table(r)
    as.integer(names(tab)[which.max(tab)])
  }))  
}


# handle missing positions (mutation never observed)
for (i in which(is.na(pos))) {
  # guess from mutation annotation
  toks <- strsplit(sites[i], ":")[[1]]
  if (length(toks) == 1) {
    # nucleotide substitution, parse position directly
    num <- re.findall("\\d+", toks[1])
    pos[i] <- as.integer(num)
  } 
  else if (toks[1] == "del") {
    # deletion annotation also contains position
    pos[i] <- as.integer(toks[2])
  }
  else {
    # use first codon position for AA substitution
    # TODO: Error handling
    start_pos <- orfs[[toks[2]]][1]  # look up ref coord
    codon <- as.integer(re.findall("\\d+", toks[3]))
    pos[i] <- start_pos + (codon-1)*3
  }
}


# import coverage data to supplement missing coverage
cvr2 <- sapply(cfiles, function(f) {
  coverage <- read.csv(f, stringsAsFactors = FALSE)
  # NOTE: coverage$position is 0-index, pos is 1-index
  idx <- match(pos, coverage$position+1)
  coverage$coverage[idx]
})
cvr2 <- as.data.frame(cvr2)
row.names(cvr2) <- sites
names(cvr2) <- sample.id


if (any(dim(cvr) != dim(cvr2))) stop("Mismatch in coverage matrices")
for (i in 1:nrow(cvr)) {
  for (j in 1:ncol(cvr)) {
    if (is.na(cvr[i,j])) {
      # fill in missing values from coverage files
      cvr[i,j] <- cvr2[i,j]
    }
    if (cvr[i,j] > 0 & is.na(counts[i,j])) {
      # set missing counts to zero if coverage exists
      counts[i,j] <- 0
    }
  }
}

# convert to integer counts and transpose so mutations are columns
counts <- as.data.frame(t(counts*cvr))
cvr <- as.data.frame(t(cvr))


# parse metadata, dealing with varying header labels and date formats
metadata <- data.frame(sample=sample.id)
metadata$lab <- sapply(cfiles, function(x) {
  tokens <- strsplit(x, "/")[[1]]
  tokens[length(tokens)-2]
})
metadata$coldate <- rep(NA, times=nrow(counts))
metadata$site <- rep(NA, times=nrow(counts))

if (!is.na(metafile)) {
  meta <- read.csv(metafile)
  #idx <- match(counts$sample, meta[,which(grepl("sample\\.ID", names(meta)))])
  r1.fn <- meta[,which(grepl("[Rr]1\\.fastq\\.filename", names(meta)))]
  idx <- match(metadata$sample, sapply(r1.fn, function(x) {
    strsplit(as.character(x), "_")[[1]][1]
  }))
  
  # parse sample collection dates
  date.col <- which(grepl("collection\\.date", names(meta)))
  if (is.na(date.col)) {
    warning("Failed to locate sample collection date column.")
  } else {
    date.str <- meta[idx, date.col]
    metadata$coldate <- as.Date(parse_date_time(date.str, c("mdy", "dmy", "ymd")))
  }
  
  # parse sampling location
  loc.col <- which(grepl("location.name", names(meta)))
  if (is.na(loc.col)) {
    warning("Failed to locate sampling location in metadata")
  } else {
    metadata$site <- meta[idx, loc.col]
  }
}

# sort by site and collection date
idx <- order(metadata$site, metadata$coldate, metadata$sample, decreasing=T)
metadata <- metadata[idx, ]
counts <- counts[idx, ]
cvr <- cvr[idx, ]

source("scripts/provoc_optim.R")
source("scripts/astronomize.R")
varmat <- astronomize(path = "constellations")
varmat <- varmat[row.names(varmat) %in% lineages,]
varmat <- varmat[, colSums(varmat) > 0]

for(i in seq_along(metadata$sample)) {
  t1 <- Sys.time()
  coco <- data.frame(
    count = as.numeric(counts[i, ]),
    coverage = as.numeric(cvr[i, ]),
    mutation = sites
  )
  coco <- coco[complete.cases(coco),]
  varmati <- varmat[, coco$mutation]

  est <- provoc_optim(coco, varmati)$res_df[, c("rho", "variant")]
  est$sample <- metadata$sample[i]

  boots <- replicate(100, {
    coco_boot <- data.frame(mutation = coco$mutation,
      coverage = rpois(nrow(coco), coco$coverage))
    # Multiply by 0.999 because sometimes integer/double is larger than 1
      # even when integer == double
    coco_boot$count <- rbinom(nrow(coco), size = coco_boot$coverage, 
      prob = 0.999*coco$count/coco$coverage)
    coco_boot <- coco_boot[complete.cases(coco_boot), ]
    varmat_boot <- varmati[, coco_boot$mutation]
    provoc_optim(coco_boot, varmat_boot)$res_df[, "rho"]
  })
  esti <- data.frame(lineage = est$variant, 
    sample = metadata$sample[i],
    probs = est$rho,
    lower.95 = apply(boots, 1, quantile, prob = 0.025),
    upper.95 = apply(boots, 1, quantile, prob = 0.975))

  if(i == 1) {
    estimate <- esti
  } else {
    estimate <- rbind(estimate, esti)
  }
  print(paste0("Loop ", i, " of ", nrow(metadata), " took ",
    round(difftime(Sys.time(), t1, units = "secs"), 2), 
    " secs."))
}

# For exploration - remove if/when satisfied
library(ggplot2)
ggplot(estimate) +
    aes(x = sample, y = probs, ymin = lower.95, ymax = upper.95, colour = lineage) +
    geom_point() + geom_errorbar()

# write output JSON
#output <- list(counts=counts, coverage=cvr, metadata=metadata,
#               estimate=estimate, lineage=lineage, run.dir=run.dir)
#jsonlite::write_json(output, outfile, pretty=TRUE)

